{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787b26fd-8c25-4f16-ab2b-4dd2479954e2",
   "metadata": {},
   "source": [
    "# Neural networks and deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "104f662f-8abc-4556-a166-30e765fbc554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'clothing-dataset-small'...\n",
      "remote: Enumerating objects: 3839, done.\u001b[K\n",
      "remote: Counting objects: 100% (400/400), done.\u001b[Kunting objects:  45% (180/400)\u001b[K\n",
      "remote: Compressing objects: 100% (400/400), done.\u001b[K\n",
      "remote: Total 3839 (delta 9), reused 385 (delta 0), pack-reused 3439 (from 1)\u001b[K\n",
      "Receiving objects: 100% (3839/3839), 100.58 MiB | 33.08 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/alexeygrigorev/clothing-dataset-small.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e783a16c-cc18-4a19-96fe-7d45a9855fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08bdb20c-fc0e-45c4-945b-335ca3969f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a043ba4-c34d-46eb-90a9-90fdeab93d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d906cad-f18e-4009-86bd-6fbabc5a4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './clothing-dataset-small/train/t-shirt'\n",
    "name = '5f0a3fa0-6a3d-4b68-b213-72766a643de7.jpg'\n",
    "fullname = f'{path}/{name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6dd5489-acdd-483a-aa4d-68832d3158f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(fullname, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9fcad21-e2d0-4b39-aa41-6f83e8f95829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 299, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81cb69-70b1-4195-8f41-43a34c5a6ec4",
   "metadata": {},
   "source": [
    "## Pre-trained convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43d598-0d4a-44aa-bd2a-53bb9fba037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2659a19-ce18-437d-84d8-f48f402a7121",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xception(weights='imagenet', input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81c644-31b3-410b-8a26-4064f7b4c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79221d-fcf4-46eb-a1d0-75303245ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf539a70-8f83-48f9-9231-fd160667fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cef463-5bdc-4112-9e7e-671f5e328fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d6d24-58cf-4849-aa30-d88249cbe1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686039d-e209-42eb-a463-1d688f01f934",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84d865-74be-4c68-94d7-9b6f3971a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c8be1-0c7d-43ab-ace7-5bfe31d3c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85e999-05ca-47d1-b63a-c573587295f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2b8b2-34d1-470c-b415-23d2dead6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350203e-d20f-4d6c-be86-35fd4ed39e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb67a45-ec80-4188-8759-f113c7e8c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd715a-bba5-4099-a902-d1d1dfe9f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(150, 150, 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "base = base_model(inputs, training=False)\n",
    "\n",
    "vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "\n",
    "outputs = keras.layers.Dense(10)(vectors)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6174aa7-ec3e-4253-9cf2-654c0acc68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057d222d-74ce-4930-8ff2-c0f4070788a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cca848-7300-494c-8a7b-d3e6117853a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef417c2-2752-49a2-8660-831c2f9c0ad6",
   "metadata": {},
   "source": [
    "## Adjusting the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755574de-fc48-4213-99a7-8e3193da6c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    outputs = keras.layers.Dense(10)(vectors)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb4379-2cdd-45e7-ba34-3b89ca0f9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "for lr in [0.0001, 0.001, 0.01, 0.1]:\n",
    "    print(lr)\n",
    "\n",
    "    model = make_model(learning_rate=lr)\n",
    "    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "    scores[lr] = history.history\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f03bd-d74a-49dd-9eb2-ff61fca3a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del scores[0.1]\n",
    "del scores[0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac870c0-e5ef-42a7-af8b-d5bd6a8f15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % lr))\n",
    "\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dddd308-2d0c-4e4a-a6f8-94cae06d5ade",
   "metadata": {},
   "source": [
    "## Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265565d-b558-4c14-a1cc-e11e68611e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_v1.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d9650-b16d-47f9-9162-0b5ef2d349b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chechpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'xception_v1_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd4ec85-aadc-4a1c-9d7a-f400b881ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = make_model(learning_rate=learning_rate)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[chechpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70cba53-c6ba-4749-a1f5-43244273caf9",
   "metadata": {},
   "source": [
    "## Adding more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f997708-1180-417a-849c-71796c1e2728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01, size_inner=100):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(inner)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23d32d-dd9b-4f13-8e9b-007184c61bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for size in [10, 100, 1000]:\n",
    "    print(size)\n",
    "\n",
    "    model = make_model(learning_rate=learning_rate, size_inner=size)\n",
    "    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "    scores[size] = history.history\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d79be-2021-465b-ad85-0a0b816cd593",
   "metadata": {},
   "outputs": [],
   "source": [
    "for size, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % size))\n",
    "\n",
    "plt.xticks(np.arange(10))\n",
    "plt.yticks([0.78, 0.80, 0.82, 0.825, 0.83])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d85e7-dbf9-4463-a92e-21f2817a5e73",
   "metadata": {},
   "source": [
    "## Regularization and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb71aa-90fa-4c26-bf1c-86133c10bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01, size_inner=100, droprate=0.5):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    drop = keras.layers.Dropout(droprate)(inner)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(drop)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629d052-aaef-4906-9cc4-d12adc0e7ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "size = 100\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for droprate in [0.0, 0.2, 0.5, 0.8]:\n",
    "    print(droprate)\n",
    "\n",
    "    model = make_model(\n",
    "        learning_rate=learning_rate,\n",
    "        size_inner=size,\n",
    "        droprate=droprate\n",
    "    )\n",
    "\n",
    "    history = model.fit(train_ds, epochs=30, validation_data=val_ds)\n",
    "    scores[droprate] = history.history\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c752e-e386-4ef6-afdf-c1214f486367",
   "metadata": {},
   "outputs": [],
   "source": [
    "for droprate, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % droprate))\n",
    "\n",
    "plt.ylim(0.78, 0.86)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb0cf7-4619-4e28-bba4-24aab432551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = scores[0.0]\n",
    "plt.plot(hist['val_accuracy'], label=0.0)\n",
    "\n",
    "hist = scores[0.2]\n",
    "plt.plot(hist['val_accuracy'], label=0.2)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31a43f-a1ef-4e75-b7ba-e3ed0bebf8fa",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8fabc-9e4e-4c93-8837-5b465e1af0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "#     vertical_flip=True,\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b496c-ce68-4f40-b829-2ac98608450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "size = 100\n",
    "droprate = 0.2\n",
    "\n",
    "model = make_model(\n",
    "    learning_rate=learning_rate,\n",
    "    size_inner=size,\n",
    "    droprate=droprate\n",
    ")\n",
    "\n",
    "history = model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beaf17e-6051-47df-ab03-9aaeae86eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['val_accuracy'], label='val')\n",
    "plt.plot(hist['accuracy'], label='train')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b76f23-f1f6-4fe6-9c35-432ed6cb1c2a",
   "metadata": {},
   "source": [
    "## Training a larger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6a927-0c63-41d2-b868-601424d9c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_size=150, learning_rate=0.01, size_inner=100,\n",
    "               droprate=0.5):\n",
    "\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(input_size, input_size, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    drop = keras.layers.Dropout(droprate)(inner)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(drop)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6648d8-5153-4263-b63c-df5d6246ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f77ab-b52a-4c3d-a671-0eaa95889189",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f8aa7-d92e-4d9c-afd0-ce32a20da227",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'xception_v4_1_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f44ece-a74a-452c-91b1-dfebb1f5e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "size = 100\n",
    "droprate = 0.2\n",
    "\n",
    "model = make_model(\n",
    "    input_size=input_size,\n",
    "    learning_rate=learning_rate,\n",
    "    size_inner=size,\n",
    "    droprate=droprate\n",
    ")\n",
    "\n",
    "history = model.fit(train_ds, epochs=50, validation_data=val_ds,\n",
    "                   callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ce5cc-674f-4ce0-9002-77d7530e0a48",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53d777-1768-4bfa-97a7-2f37df3b9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa98e2-e01c-40cb-a32a-d299f7e16859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4278e55-9224-4276-8631-1b7ccf2522ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_ds = test_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/test',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9e4f9-991b-45ab-81c6-bf428951f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('xception_v4_1_13_0.903.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017baa23-cf3e-432f-99c4-87f551b50233",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed58741-829d-49a2-9bb6-44095600ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'clothing-dataset-small/test/pants/c8d21106-bbdb-4e8d-83e4-bf3d14e54c16.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10822a7f-6f96-46ad-90be-ee8b53137541",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(path, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e43f9-7e01-4687-a5d6-4db067e9a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3694c877-4667-4980-bde1-4f3383cd38b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img)\n",
    "X = np.array([x])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f3c70d-294c-4a50-b5a3-6c4aef129242",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910a7cf-d090-4393-af3a-ccc38b9d7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93870752-4909-4331-b206-603b36e7a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee67bf-0b8a-44d0-b033-d3ac84135f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(classes, pred[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
